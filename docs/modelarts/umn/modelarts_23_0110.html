<a name="modelarts_23_0110"></a><a name="modelarts_23_0110"></a>

<h1 class="topictitle1">Conversion Templates</h1>
<div id="body8662426"><p id="modelarts_23_0110__en-us_topic_0177612243_p489090175617">ModelArts provides the following conversion templates based on different AI frameworks:</p>
<ul id="modelarts_23_0110__en-us_topic_0177612243_ul1042617555556"><li id="modelarts_23_0110__en-us_topic_0177612243_li1542755565520"><a href="#modelarts_23_0110__en-us_topic_0177612243_section47553019134">TF-FrozenGraph-To-Ascend-C32</a></li></ul>
<div class="section" id="modelarts_23_0110__en-us_topic_0177612243_section47553019134"><a name="modelarts_23_0110__en-us_topic_0177612243_section47553019134"></a><a name="en-us_topic_0177612243_section47553019134"></a><h4 class="sectiontitle">TF-FrozenGraph-To-Ascend-C32</h4><p id="modelarts_23_0110__en-us_topic_0177612243_p14225733163016">Convert the model trained by the TensorFlow framework and saved in <span class="filepath" id="modelarts_23_0110__en-us_topic_0177612243_filepath980710496516"><b>frozen_graph</b></span> format. The converted model can run on the Ascend. The custom operators (TBE operators) developed based on Tensor Based Engine (TBE) can be used for conversion.</p>

<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="modelarts_23_0110__en-us_topic_0177612243_table397415449135" frame="border" border="1" rules="all"><caption><b>Table 1 </b>Advanced settings of the custom operator conversion template</caption><thead align="left"><tr id="modelarts_23_0110__en-us_topic_0177612243_row194110845913"><th align="left" class="cellrowborder" valign="top" width="26%" id="mcps1.3.3.3.2.3.1.1"><p id="modelarts_23_0110__en-us_topic_0177612243_p15413812592">Parameter</p>
</th>
<th align="left" class="cellrowborder" valign="top" width="74%" id="mcps1.3.3.3.2.3.1.2"><p id="modelarts_23_0110__en-us_topic_0177612243_p54117885910">Description</p>
</th>
</tr>
</thead>
<tbody><tr id="modelarts_23_0110__en-us_topic_0177612243_row106358145915"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.3.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_p46215818597">input_shape</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.3.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_p1563482590">Enter the shape of the input data of the model, for example, <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue59442311093"><b>input_name1:n1,c1,h1,w1;input_name2:n2,c2,h2,w2</b></span>. <strong id="modelarts_23_0110__en-us_topic_0177612243_b893591412252">input_name</strong> must be the node name in the network model before model conversion. This parameter is mandatory when the model has dynamic shape input. For example, in <strong id="modelarts_23_0110__en-us_topic_0177612243_b698707924">input_name1:? ,h,w,c</strong>, the question mark (?) indicates the batch size, that is, the number of images processed at a time. It is used to convert the original model with a dynamic shape into an offline model with a fixed shape. The batch feature is not supported. The batch value of the <strong id="modelarts_23_0110__en-us_topic_0177612243_b1706552783">input_shape</strong> can only be <strong id="modelarts_23_0110__en-us_topic_0177612243_b2140208535">1</strong>. During the conversion, the system parses the input model to obtain the input tensor and prints it in the log. If you do not know the input tensor of the used model, refer to the parsing result in the log.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_row19631781592"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.3.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_p56328165914">input_format</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.3.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_p17636817599"><strong id="modelarts_23_0110__en-us_topic_0177612243_b36441037201214">NCHW</strong> and <strong id="modelarts_23_0110__en-us_topic_0177612243_b146447370126">NHWC</strong> are supported. The default format is <strong id="modelarts_23_0110__en-us_topic_0177612243_b564523791217">NHWC</strong>. For the TensorFlow framework, the default value is <strong id="modelarts_23_0110__en-us_topic_0177612243_b0709161391319">NHWC</strong>. To use the NCHW format, you need to specify <strong id="modelarts_23_0110__en-us_topic_0177612243_b960312684">NCHW</strong>. For the Caffe framework, only the NCHW format is supported.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_row16643835910"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.3.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_p763118105920">out_nodes</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.3.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_p1664148105913">Specifies the output node, for example, <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue91421057144"><b>node_name1:0;node_name1:1;node_name2:0</b></span>. <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue71472510140"><b>node_name</b></span> must be the node name in the network model before model conversion. The digit after each colon (:) indicates the sequence number of the output. For example, <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue17147551145"><b>node_name1:0</b></span> indicates the 0th output of <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue914895101410"><b>node_name1</b></span>. If the output node is not specified, the output of the last operator layer serves as the model output by default. To check the parameters of a specific operator layer, specify the operator layer by using this parameter. During the conversion, the system parses the input model to obtain the output node and prints it in the log. If you do not know the input tensor of the used model, refer to the parsing result in the log.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_row1565586592"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.3.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_p56417825913">net_format</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.3.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_p265138145912">Specifies the preferred data format for network operators. Possible values are <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue129421738101419"><b>ND</b></span> (N cannot be more than 4) and <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue11947113851410"><b>5D</b></span>. This parameter only takes effect if the input data of operators on the network supports both <strong id="modelarts_23_0110__en-us_topic_0177612243_b152073508140">ND</strong> and <strong id="modelarts_23_0110__en-us_topic_0177612243_b52125501146">5D</strong> formats. <strong id="modelarts_23_0110__en-us_topic_0177612243_b318883287">ND</strong> indicates that operators in the model are converted into the NCHW format. <strong id="modelarts_23_0110__en-us_topic_0177612243_b34028963">5D</strong> indicates that . <strong id="modelarts_23_0110__en-us_topic_0177612243_b9120105215141">5D</strong> is the default value.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_row16658818594"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.3.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_p10657875910">fp16_high_prec</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.3.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_p5651286592">Specifies whether to generate a high-precision <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_parmvalue950810552147"><b>FP16 Davinci</b></span> model. <strong id="modelarts_23_0110__en-us_topic_0177612243_b1223761113475">0</strong> is the default value, indicating that a common FP16 Da Vinci model with better inference performance is generated. The value <strong id="modelarts_23_0110__en-us_topic_0177612243_b1997099573">1</strong> indicates that a high-precision FP16 Da Vinci model with better inference precision is generated. High-precision models support only Caffe operators (Convolution, Pooling, and FullConnection) and TensorFlow operators (tf.nn.conv2d and tf.nn.max_poo).</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_row1966786596"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.3.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_p196514810592">output_type</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.3.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_p26617835920"><strong id="modelarts_23_0110__en-us_topic_0177612243_b882384624915">FP32</strong> is the default value and is recommended for classification and detection networks. For image super-resolution networks, UINT8 is recommended for better inference performance.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_row9664895915"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.3.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_p18661089599"><span class="parmname" id="modelarts_23_0110__en-us_topic_0177612243_parmname63821932132214"><b>enable_l2dynamic</b></span></p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.3.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_p1966148145919">L2 dynamic optimization switch. This parameter may affect the inference performance of the network model. If the performance does not meet the requirement, you can disable this function to verify the impact on the performance. <strong id="modelarts_23_0110__en-us_topic_0177612243_b18661938182217">true</strong> is the default value, indicating that L2 dynamic optimization is enabled. <strong id="modelarts_23_0110__en-us_topic_0177612243_b970193832213">false</strong> indicates that L2 dynamic optimization is disabled.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="modelarts_23_0110__en-us_topic_0177612243_section678819203143"><h4 class="sectiontitle">TF-SavedModel-To-Ascend-C32</h4><p id="modelarts_23_0110__en-us_topic_0177612243_p1695850123019">Convert the model trained by the TensorFlow framework and saved in <span class="filepath" id="modelarts_23_0110__en-us_topic_0177612243_filepath1406038745"><b>saved_model</b></span> format. The converted model can run on the Ascend. The custom operators (TE operators) developed based on TE can be used for conversion.</p>

<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="modelarts_23_0110__en-us_topic_0177612243_table17573123151414" frame="border" border="1" rules="all"><caption><b>Table 2 </b>Advanced settings of the custom operator conversion template</caption><thead align="left"><tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row194110845913"><th align="left" class="cellrowborder" valign="top" width="26%" id="mcps1.3.4.3.2.3.1.1"><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p15413812592">Parameter</p>
</th>
<th align="left" class="cellrowborder" valign="top" width="74%" id="mcps1.3.4.3.2.3.1.2"><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p54117885910">Description</p>
</th>
</tr>
</thead>
<tbody><tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row106358145915"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.4.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p46215818597">input_shape</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.4.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p1563482590">Enter the shape of the input data of the model, for example, <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue59442311093"><b>input_name1:n1,c1,h1,w1;input_name2:n2,c2,h2,w2</b></span>. <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b893591412252">input_name</strong> must be the node name in the network model before model conversion. This parameter is mandatory when the model has dynamic shape input. For example, in <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b698707924">input_name1:? ,h,w,c</strong>, the question mark (?) indicates the batch size, that is, the number of images processed at a time. It is used to convert the original model with a dynamic shape into an offline model with a fixed shape. The batch feature is not supported. The batch value of the <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b1706552783">input_shape</strong> can only be <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b2140208535">1</strong>. During the conversion, the system parses the input model to obtain the input tensor and prints it in the log. If you do not know the input tensor of the used model, refer to the parsing result in the log.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row19631781592"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.4.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p56328165914">input_format</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.4.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p17636817599"><strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b36441037201214">NCHW</strong> and <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b146447370126">NHWC</strong> are supported. The default format is <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b564523791217">NHWC</strong>. For the TensorFlow framework, the default value is <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b0709161391319">NHWC</strong>. To use the NCHW format, you need to specify <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b960312684">NCHW</strong>. For the Caffe framework, only the NCHW format is supported.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row16643835910"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.4.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p763118105920">out_nodes</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.4.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p1664148105913">Specifies the output node, for example, <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue91421057144"><b>node_name1:0;node_name1:1;node_name2:0</b></span>. <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue71472510140"><b>node_name</b></span> must be the node name in the network model before model conversion. The digit after each colon (:) indicates the sequence number of the output. For example, <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue17147551145"><b>node_name1:0</b></span> indicates the 0th output of <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue914895101410"><b>node_name1</b></span>. If the output node is not specified, the output of the last operator layer serves as the model output by default. To check the parameters of a specific operator layer, specify the operator layer by using this parameter. During the conversion, the system parses the input model to obtain the output node and prints it in the log. If you do not know the input tensor of the used model, refer to the parsing result in the log.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row1565586592"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.4.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p56417825913">net_format</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.4.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p265138145912">Specifies the preferred data format for network operators. Possible values are <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue129421738101419"><b>ND</b></span> (N cannot be more than 4) and <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue11947113851410"><b>5D</b></span>. This parameter only takes effect if the input data of operators on the network supports both <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b152073508140">ND</strong> and <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b52125501146">5D</strong> formats. <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b318883287">ND</strong> indicates that operators in the model are converted into the NCHW format. <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b34028963">5D</strong> indicates that . <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b9120105215141">5D</strong> is the default value.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row16658818594"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.4.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p10657875910">fp16_high_prec</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.4.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p5651286592">Specifies whether to generate a high-precision <span class="parmvalue" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmvalue950810552147"><b>FP16 Davinci</b></span> model. <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b1223761113475">0</strong> is the default value, indicating that a common FP16 Da Vinci model with better inference performance is generated. The value <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b1997099573">1</strong> indicates that a high-precision FP16 Da Vinci model with better inference precision is generated. High-precision models support only Caffe operators (Convolution, Pooling, and FullConnection) and TensorFlow operators (tf.nn.conv2d and tf.nn.max_poo).</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row1966786596"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.4.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p196514810592">output_type</p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.4.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p26617835920"><strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b882384624915">FP32</strong> is the default value and is recommended for classification and detection networks. For image super-resolution networks, UINT8 is recommended for better inference performance.</p>
</td>
</tr>
<tr id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_row9664895915"><td class="cellrowborder" valign="top" width="26%" headers="mcps1.3.4.3.2.3.1.1 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p18661089599"><span class="parmname" id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_parmname63821932132214"><b>enable_l2dynamic</b></span></p>
</td>
<td class="cellrowborder" valign="top" width="74%" headers="mcps1.3.4.3.2.3.1.2 "><p id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_p1966148145919">L2 dynamic optimization switch. This parameter may affect the inference performance of the network model. If the performance does not meet the requirement, you can disable this function to verify the impact on the performance. <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b18661938182217">true</strong> is the default value, indicating that L2 dynamic optimization is enabled. <strong id="modelarts_23_0110__en-us_topic_0177612243_en-us_topic_0177612243_b970193832213">false</strong> indicates that L2 dynamic optimization is disabled.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div>
<div class="familylinks">
<div class="parentlink"><strong>Parent topic:</strong> <a href="modelarts_23_0106.html">Model Compression and Conversion</a></div>
</div>
</div>

