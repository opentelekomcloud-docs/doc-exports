<a name="modelarts_23_0093"></a><a name="modelarts_23_0093"></a>

<h1 class="topictitle1">Specifications for Compiling Model Inference Code</h1>
<div id="body8662426"><p id="modelarts_23_0093__en-us_topic_0172466150_p133771553267">This section describes how to compile model inference code in ModelArts. The following also provides an example of inference code for the TensorFlow engine and an example of customizing inference logic in an inference script.</p>
<div class="section" id="modelarts_23_0093__en-us_topic_0172466150_section91713215288"><h4 class="sectiontitle">Specifications for Compiling Inference Code</h4><ol id="modelarts_23_0093__en-us_topic_0172466150_ol15430143745316"><li id="modelarts_23_0093__en-us_topic_0172466150_li7430203716533">All custom Python code must be inherited from the BaseService class. <a href="#modelarts_23_0093__en-us_topic_0172466150_table55021545175412">Table 1</a> lists the import statements of different types of model parent classes.
<div class="tablenoborder"><a name="modelarts_23_0093__en-us_topic_0172466150_table55021545175412"></a><a name="en-us_topic_0172466150_table55021545175412"></a><table cellpadding="4" cellspacing="0" summary="" id="modelarts_23_0093__en-us_topic_0172466150_table55021545175412" width="90%" frame="border" border="1" rules="all"><caption><b>Table 1 </b>Import statements of the <strong id="modelarts_23_0093__en-us_topic_0172466150_b5592524103316">BaseService</strong> class</caption><thead align="left"><tr id="modelarts_23_0093__en-us_topic_0172466150_row8538104512544"><th align="left" class="cellrowborder" valign="top" width="13.05%" id="mcps1.3.2.2.1.2.2.4.1.1"><p id="modelarts_23_0093__en-us_topic_0172466150_p5538104519547">Model Type</p>
</th>
<th align="left" class="cellrowborder" valign="top" width="12.64%" id="mcps1.3.2.2.1.2.2.4.1.2"><p id="modelarts_23_0093__en-us_topic_0172466150_p1453804585415">Parent Class</p>
</th>
<th align="left" class="cellrowborder" valign="top" width="74.31%" id="mcps1.3.2.2.1.2.2.4.1.3"><p id="modelarts_23_0093__en-us_topic_0172466150_p3538164519546">Import Statement</p>
</th>
</tr>
</thead>
<tbody><tr id="modelarts_23_0093__en-us_topic_0172466150_row175381645175416"><td class="cellrowborder" valign="top" width="13.05%" headers="mcps1.3.2.2.1.2.2.4.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p18538445155411">TensorFlow</p>
</td>
<td class="cellrowborder" valign="top" width="12.64%" headers="mcps1.3.2.2.1.2.2.4.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p653815455548">TfServingBaseService</p>
</td>
<td class="cellrowborder" valign="top" width="74.31%" headers="mcps1.3.2.2.1.2.2.4.1.3 "><p id="modelarts_23_0093__en-us_topic_0172466150_p2538124516544">from model_service.tfserving_model_service import TfServingBaseService</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row105381145195413"><td class="cellrowborder" valign="top" width="13.05%" headers="mcps1.3.2.2.1.2.2.4.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p753884545414">MXNet</p>
</td>
<td class="cellrowborder" valign="top" width="12.64%" headers="mcps1.3.2.2.1.2.2.4.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p85381445185418">MXNetBaseService</p>
</td>
<td class="cellrowborder" valign="top" width="74.31%" headers="mcps1.3.2.2.1.2.2.4.1.3 "><p id="modelarts_23_0093__en-us_topic_0172466150_p953813457540">from mms.model_service.mxnet_model_service import MXNetBaseService</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row205381745145415"><td class="cellrowborder" valign="top" width="13.05%" headers="mcps1.3.2.2.1.2.2.4.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p8538164555417">PyTorch</p>
</td>
<td class="cellrowborder" valign="top" width="12.64%" headers="mcps1.3.2.2.1.2.2.4.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p1453811458545">PTServingBaseService</p>
</td>
<td class="cellrowborder" valign="top" width="74.31%" headers="mcps1.3.2.2.1.2.2.4.1.3 "><p id="modelarts_23_0093__en-us_topic_0172466150_p105381445125414">from model_service.pytorch_model_service import PTServingBaseService</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row19420104110717"><td class="cellrowborder" valign="top" width="13.05%" headers="mcps1.3.2.2.1.2.2.4.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p34201441972">Pyspark</p>
</td>
<td class="cellrowborder" valign="top" width="12.64%" headers="mcps1.3.2.2.1.2.2.4.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p842116419713">SparkServingBaseService</p>
</td>
<td class="cellrowborder" valign="top" width="74.31%" headers="mcps1.3.2.2.1.2.2.4.1.3 "><p id="modelarts_23_0093__en-us_topic_0172466150_p206411101888">from model_service.spark_model_service import SparkServingBaseService</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row62955965118"><td class="cellrowborder" valign="top" width="13.05%" headers="mcps1.3.2.2.1.2.2.4.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p1329613925117">Caffe</p>
</td>
<td class="cellrowborder" valign="top" width="12.64%" headers="mcps1.3.2.2.1.2.2.4.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p132965918515">CaffeBaseService</p>
</td>
<td class="cellrowborder" valign="top" width="74.31%" headers="mcps1.3.2.2.1.2.2.4.1.3 "><p id="modelarts_23_0093__en-us_topic_0172466150_p829619965117">from model_service.caffe_model_service import CaffeBaseService</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row17610103452920"><td class="cellrowborder" valign="top" width="13.05%" headers="mcps1.3.2.2.1.2.2.4.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p148249131016">XGBoost</p>
</td>
<td class="cellrowborder" valign="top" width="12.64%" headers="mcps1.3.2.2.1.2.2.4.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p182411131007">XgSklServingBaseService</p>
</td>
<td class="cellrowborder" valign="top" width="74.31%" headers="mcps1.3.2.2.1.2.2.4.1.3 "><p id="modelarts_23_0093__en-us_topic_0172466150_p182415131101">from model_service.python_model_service import XgSklServingBaseService</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row11786153892914"><td class="cellrowborder" valign="top" width="13.05%" headers="mcps1.3.2.2.1.2.2.4.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p347261718013">Scikit_Learn</p>
</td>
<td class="cellrowborder" valign="top" width="12.64%" headers="mcps1.3.2.2.1.2.2.4.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p647251710016">XgSklServingBaseService</p>
</td>
<td class="cellrowborder" valign="top" width="74.31%" headers="mcps1.3.2.2.1.2.2.4.1.3 "><p id="modelarts_23_0093__en-us_topic_0172466150_p204721175016">from model_service.python_model_service import XgSklServingBaseService</p>
</td>
</tr>
</tbody>
</table>
</div>
</li><li id="modelarts_23_0093__en-us_topic_0172466150_li1363203845315">The following methods can be rewritten:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="modelarts_23_0093__en-us_topic_0172466150_table119897712529" frame="border" border="1" rules="all"><caption><b>Table 2 </b>Methods to be rewritten</caption><thead align="left"><tr id="modelarts_23_0093__en-us_topic_0172466150_row18990187175216"><th align="left" class="cellrowborder" valign="top" width="26.36%" id="mcps1.3.2.2.2.1.2.3.1.1"><p id="modelarts_23_0093__en-us_topic_0172466150_p79906795211">Method</p>
</th>
<th align="left" class="cellrowborder" valign="top" width="73.64%" id="mcps1.3.2.2.2.1.2.3.1.2"><p id="modelarts_23_0093__en-us_topic_0172466150_p59901773525">Description</p>
</th>
</tr>
</thead>
<tbody><tr id="modelarts_23_0093__en-us_topic_0172466150_row1899007155210"><td class="cellrowborder" valign="top" width="26.36%" headers="mcps1.3.2.2.2.1.2.3.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p999087135218">__init__(self, model_name, model_path)</p>
</td>
<td class="cellrowborder" valign="top" width="73.64%" headers="mcps1.3.2.2.2.1.2.3.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p1799014717525">Initialization method, which is suitable for models created based on deep learning frameworks. Models and labels are loaded using this method. This method must be rewritten for models based on PyTorch and Caffe to implement the model loading logic.</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row102715331426"><td class="cellrowborder" valign="top" width="26.36%" headers="mcps1.3.2.2.2.1.2.3.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p19174739144215">__init__(self, model_path)</p>
</td>
<td class="cellrowborder" valign="top" width="73.64%" headers="mcps1.3.2.2.2.1.2.3.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p1856318404588">Initialization method, which is suitable for models created based on machine learning frameworks. The model path (<strong id="modelarts_23_0093__en-us_topic_0172466150_b1485241344319">self.model_path</strong>) is initialized using this method. In Spark_MLlib, this method also initializes SparkSession (<strong id="modelarts_23_0093__en-us_topic_0172466150_b12679194016432">self.spark</strong>).</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row20990187165211"><td class="cellrowborder" valign="top" width="26.36%" headers="mcps1.3.2.2.2.1.2.3.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p4990177155212">_preprocess(self, data)</p>
</td>
<td class="cellrowborder" valign="top" width="73.64%" headers="mcps1.3.2.2.2.1.2.3.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p2990171521">Preprocess method, which is called before an inference request and is used to convert the original request data of an API into the expected input data of a model</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row79900716522"><td class="cellrowborder" valign="top" width="26.36%" headers="mcps1.3.2.2.2.1.2.3.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p1199097165217">_inference(self, data)</p>
</td>
<td class="cellrowborder" valign="top" width="73.64%" headers="mcps1.3.2.2.2.1.2.3.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p209905755218">Inference request method. You are not advised to rewrite the method because once the method is rewritten, the built-in inference process of ModelArts will be overwritten and the custom inference logic will run.</p>
</td>
</tr>
<tr id="modelarts_23_0093__en-us_topic_0172466150_row1499097145219"><td class="cellrowborder" valign="top" width="26.36%" headers="mcps1.3.2.2.2.1.2.3.1.1 "><p id="modelarts_23_0093__en-us_topic_0172466150_p19901173520">_postprocess(self, data)</p>
</td>
<td class="cellrowborder" valign="top" width="73.64%" headers="mcps1.3.2.2.2.1.2.3.1.2 "><p id="modelarts_23_0093__en-us_topic_0172466150_p1990157165215">Postprocess method, which is called after an inference request is complete and is used to convert the model output to the API output</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="note" id="modelarts_23_0093__en-us_topic_0172466150_note27641755185116"><img src="public_sys-resources/note_3.0-en-us.png"><span class="notetitle"> </span><div class="notebody"><ul id="modelarts_23_0093__en-us_topic_0172466150_ul87643551511"><li id="modelarts_23_0093__en-us_topic_0172466150_li127631455115114">You can choose to rewrite the preprocess and postprocess methods to implement preprocessing of the API input and postprocessing of the inference output.</li><li id="modelarts_23_0093__en-us_topic_0172466150_li57646552514">Rewriting the init method of the BaseService inheritance class may cause a model to run abnormally.</li></ul>
</div></div>
</li><li id="modelarts_23_0093__en-us_topic_0172466150_li135956421288"><a name="modelarts_23_0093__en-us_topic_0172466150_li135956421288"></a><a name="en-us_topic_0172466150_li135956421288"></a>The attribute that can be used is the local path where the model resides. The attribute name is <span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname3144651365"><b>self.model_path</b></span>. In addition, PySpark-based models can use <span class="filepath" id="modelarts_23_0093__en-us_topic_0172466150_filepath12582451169"><b>self.spark</b></span> to obtain the SparkSession object in <span class="filepath" id="modelarts_23_0093__en-us_topic_0172466150_filepath19569163301610"><b>customize_service.py</b></span>.<div class="note" id="modelarts_23_0093__en-us_topic_0172466150_note1854313623117"><img src="public_sys-resources/note_3.0-en-us.png"><span class="notetitle"> </span><div class="notebody"><p id="modelarts_23_0093__en-us_topic_0172466150_p954373614311">An absolute path is required for reading files in the inference code. You can obtain the absolute path of the model from the <strong id="modelarts_23_0093__en-us_topic_0172466150_b19607112010486">self.model_path</strong> attribute.</p>
<ul id="modelarts_23_0093__en-us_topic_0172466150_ul179961412802"><li id="modelarts_23_0093__en-us_topic_0172466150_li499619121010">When TensorFlow, Caffe, or MXNet is used, <strong id="modelarts_23_0093__en-us_topic_0172466150_b1573672365011">self.model_path</strong> indicates the path of the model file. See the following example:<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen1116519016110"># Store the label.json file in the model directory. The following information is read:
with open(os.path.join(self.model_path, 'label.json')) as f:
    self.label = json.load(f)</pre>
</li></ul>
<ul id="modelarts_23_0093__en-us_topic_0172466150_ul2330191515017"><li id="modelarts_23_0093__en-us_topic_0172466150_li1133013151608">When PyTorch, Scikit_Learn, or PySpark is used, <strong id="modelarts_23_0093__en-us_topic_0172466150_b065511219521">self.model_path</strong> indicates the path of the model file. See the following example:<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen37112122012"># Store the label.json file in the model directory. The following information is read:
dir_path = os.path.dirname(os.path.realpath(self.model_path))
with open(os.path.join(dir_path, 'label.json')) as f:
    self.label = json.load(f)</pre>
</li></ul>
</div></div>
</li><li id="modelarts_23_0093__en-us_topic_0172466150_li19263459185811">Two types of <strong id="modelarts_23_0093__en-us_topic_0172466150_b19340131525815">content-type</strong> APIs can be used for inputting data: <span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname132171631509"><b>multipart/form-data</b></span> and <span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname194561347015"><b>application/json</b></span><ul id="modelarts_23_0093__en-us_topic_0172466150_ul445916178594"><li id="modelarts_23_0093__en-us_topic_0172466150_li1346010176592"><span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname88821389013"><b>multipart/form-data</b></span> request<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen15898123318596">curl -X POST \
  &lt;modelarts-inference-endpoint&gt; \
  -F image1=@cat.jpg \
  -F images2=@horse.jpg</pre>
<p id="modelarts_23_0093__en-us_topic_0172466150_p584916387591">The corresponding input data is as follows:</p>
<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen94579453597">[
   {
      "image1":{
         "cat.jpg":"&lt;cat..jpg file io&gt;"
      }
   },
   {
      "image2":{
         "horse.jpg":"&lt;horse.jpg file io&gt;"
      }
   }
]</pre>
</li><li id="modelarts_23_0093__en-us_topic_0172466150_li13538112155915"><span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname1846842805"><b>application/json</b></span> request<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen9118165815591"> curl -X POST \
   &lt;modelarts-inference-endpoint&gt; \
   -d '{
    "images":"base64 encode image"
    }'</pre>
<p id="modelarts_23_0093__en-us_topic_0172466150_p12803175001">The corresponding input data is <strong id="modelarts_23_0093__en-us_topic_0172466150_b2611171111012">python dict</strong>.</p>
<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen1161215161403"> {
    "images":"base64 encode image"

 }</pre>
</li></ul>
</li></ol>
</div>
<div class="section" id="modelarts_23_0093__en-us_topic_0172466150_section0900184692811"><h4 class="sectiontitle">TensorFlow Inference Script Example</h4><div class="p" id="modelarts_23_0093__en-us_topic_0172466150_p54391313122916">The following is an example of TensorFlow MnistService.<ul id="modelarts_23_0093__en-us_topic_0172466150_ul17205712105413"><li id="modelarts_23_0093__en-us_topic_0172466150_li5205141255414">Inference code<div class="codecoloring" codetype="Python" id="modelarts_23_0093__en-us_topic_0172466150_screen692724518215"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">model_service.tfserving_model_service</span> <span class="kn">import</span> <span class="n">TfServingBaseService</span>

<span class="k">class</span> <span class="nc">mnist_service</span><span class="p">(</span><span class="n">TfServingBaseService</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">preprocessed_data</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">file_content</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">image1</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">file_content</span><span class="p">)</span>
                <span class="n">image1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">image1</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
                <span class="n">preprocessed_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">image1</span>

        <span class="k">return</span> <span class="n">preprocessed_data</span>

    <span class="k">def</span> <span class="nf">_postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">infer_output</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

            <span class="n">infer_output</span><span class="p">[</span><span class="s2">&quot;mnist_result&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="k">return</span> <span class="n">infer_output</span>
</pre></div>
</td></tr></table></div>
</li><li id="modelarts_23_0093__en-us_topic_0172466150_li4451613155419">Request<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen438073645616">curl -X POST \ <em id="modelarts_23_0093__en-us_topic_0172466150_i204261841153315">Real-time service address</em> \ -F images=@test.jpg</pre>
</li><li id="modelarts_23_0093__en-us_topic_0172466150_li12341219135417">Response<pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen664863925613">{"mnist_result": 7}</pre>
</li></ul>
</div>
<p id="modelarts_23_0093__en-us_topic_0172466150_p162859249544">The preceding code example resizes images imported to the user's form to adapt to the model input shape. The <span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname127619719576"><b>32×32</b></span> image is read from the Pillow library and resized to <span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname181111210135711"><b>1×784</b></span> to match the model input. In subsequent processing, convert the model output into a list for the RESTful API to display.</p>
</div>
<div class="section" id="modelarts_23_0093__en-us_topic_0172466150_section1874171872515"><h4 class="sectiontitle">XGBoost Inference Script Example</h4><pre class="screen" id="modelarts_23_0093__en-us_topic_0172466150_screen6171128103319"># coding:utf-8
import collections
import json
import xgboost as xgb
from model_service.python_model_service import XgSklServingBaseService


class user_Service(XgSklServingBaseService):

    # request data preprocess
    def _preprocess(self, data):
        list_data = []
        json_data = json.loads(data, object_pairs_hook=collections.OrderedDict)
        for element in json_data["data"]["req_data"]:
            array = []
            for each in element:
                array.append(element[each])
                list_data.append(array)
        return list_data

    #   predict
    def _inference(self, data):
        xg_model = xgb.Booster(model_file=self.model_path)
        pre_data = xgb.DMatrix(data)
        pre_result = xg_model.predict(pre_data)
        pre_result = pre_result.tolist()
        return pre_result

    # predict result process
    def _postprocess(self, data):
        resp_data = []
        for element in data:
            resp_data.append({"predict_result": element})
        return resp_data</pre>
<p id="modelarts_23_0093__en-us_topic_0172466150_p132638213257"></p>
</div>
<div class="section" id="modelarts_23_0093__en-us_topic_0172466150_section971394732916"><h4 class="sectiontitle">Inference Script Example of the Custom Inference Logic</h4><p id="modelarts_23_0093__en-us_topic_0172466150_p96801143018">First, define a dependency package in the configuration file. For details, see <a href="modelarts_23_0092.html#modelarts_23_0092__en-us_topic_0172466149_section119911955122011">Example of a Model Configuration File Using a Custom Dependency Package</a>. Then, use the following code example to implement the loading and inference of the model in <span class="parmname" id="modelarts_23_0093__en-us_topic_0172466150_parmname1928615313327"><b>saved_model</b></span> format.</p>
<div class="codecoloring" codetype="Python" id="modelarts_23_0093__en-us_topic_0172466150_screen147126916327"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">threading</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">from</span> <span class="nn">model_service.tfserving_model_service</span> <span class="kn">import</span> <span class="n">TfServingBaseService</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MnistService</span><span class="p">(</span><span class="n">TfServingBaseService</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span> <span class="o">=</span> <span class="n">model_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_outputs</span> <span class="o">=</span> <span class="p">{}</span>

       <span class="c1"># The label file can be loaded here and used in the post-processing function.</span>
        <span class="c1"># Directories for storing the label.txt file on OBS and in the model package</span>

        <span class="c1"># with open(os.path.join(self.model_path, 'label.txt')) as f:</span>
        <span class="c1">#     self.label = json.load(f)</span>

        <span class="c1"># Load the model in saved_model format in non-blocking mode to prevent blocking timeout.</span>
        <span class="n">thread</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_tf_sess</span><span class="p">)</span>
        <span class="n">thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_tf_sess</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Load the model in saved_model format.</span>

       <span class="c1"># The session will be reused. Do not use the with statement.</span>
        <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span>
        <span class="n">meta_graph_def</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">tag_constants</span><span class="o">.</span><span class="n">SERVING</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">signature_defs</span> <span class="o">=</span> <span class="n">meta_graph_def</span><span class="o">.</span><span class="n">signature_def</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">sess</span>

        <span class="n">signature</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># only one signature allowed</span>
        <span class="k">for</span> <span class="n">signature_def</span> <span class="ow">in</span> <span class="n">signature_defs</span><span class="p">:</span>
            <span class="n">signature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">signature_def</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">signature</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">model_signature</span> <span class="o">=</span> <span class="n">signature</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;signatures more than one, use serving_default signature&quot;</span><span class="p">)</span>
            <span class="n">model_signature</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">signature_constants</span><span class="o">.</span><span class="n">DEFAULT_SERVING_SIGNATURE_DEF_KEY</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;model signature: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model_signature</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">signature_name</span> <span class="ow">in</span> <span class="n">meta_graph_def</span><span class="o">.</span><span class="n">signature_def</span><span class="p">[</span><span class="n">model_signature</span><span class="p">]</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
            <span class="n">tensorinfo</span> <span class="o">=</span> <span class="n">meta_graph_def</span><span class="o">.</span><span class="n">signature_def</span><span class="p">[</span><span class="n">model_signature</span><span class="p">]</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">signature_name</span><span class="p">]</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">tensorinfo</span><span class="o">.</span><span class="n">name</span>
            <span class="n">op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_inputs</span><span class="p">[</span><span class="n">signature_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">op</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;model inputs: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_inputs</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">signature_name</span> <span class="ow">in</span> <span class="n">meta_graph_def</span><span class="o">.</span><span class="n">signature_def</span><span class="p">[</span><span class="n">model_signature</span><span class="p">]</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="n">tensorinfo</span> <span class="o">=</span> <span class="n">meta_graph_def</span><span class="o">.</span><span class="n">signature_def</span><span class="p">[</span><span class="n">model_signature</span><span class="p">]</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">signature_name</span><span class="p">]</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">tensorinfo</span><span class="o">.</span><span class="n">name</span>
            <span class="n">op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model_outputs</span><span class="p">[</span><span class="n">signature_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">op</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;model outputs: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_outputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># Two request modes using HTTPS</span>
        <span class="c1"># 1. The request in form-data file format is as follows: data = {&quot;Request key value&quot;:{&quot;File name&quot;:&lt;File io&gt;}}</span>
       <span class="c1"># 2. Request in JSON format is as follows: data = json.loads(&quot;JSON body transferred by the API&quot;)</span>
        <span class="n">preprocessed_data</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">file_content</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">image1</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">file_content</span><span class="p">)</span>
                <span class="n">image1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">image1</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
                <span class="n">preprocessed_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">image1</span>

        <span class="k">return</span> <span class="n">preprocessed_data</span>

    <span class="k">def</span> <span class="nf">_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;input key </span><span class="si">%s</span><span class="s2"> is not in model inputs </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;input key </span><span class="si">%s</span><span class="s2"> is not in model inputs </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
            <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_outputs</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'predict result : '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">_postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">infer_output</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mnist_result&quot;</span><span class="p">:</span> <span class="p">[]}</span>
        <span class="k">for</span> <span class="n">output_name</span><span class="p">,</span> <span class="n">results</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

            <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
                <span class="n">infer_output</span><span class="p">[</span><span class="s2">&quot;mnist_result&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">infer_output</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
</div>
</div>
<div>
<div class="familylinks">
<div class="parentlink"><strong>Parent topic:</strong> <a href="modelarts_23_0090.html">Model Package Specifications</a></div>
</div>
</div>

